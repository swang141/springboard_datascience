{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import bank marketing dataset\n",
    "import pandas as pd\n",
    "bank_full = pd.read_csv(r'C:\\Users\\wangs\\Documents\\SHAN WANG\\springBoard\\Project\\BANK MARKETING DATASET\\bank-full.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
      "4   33       unknown   single    unknown      no        1      no   no   \n",
      "\n",
      "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
      "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
      "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
      "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
      "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
      "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
      "(45211, 17)\n"
     ]
    }
   ],
   "source": [
    "print (bank_full.head())\n",
    "print (bank_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataset into trainX, trainY, testX, testY \n",
    "from sklearn.model_selection import train_test_split \n",
    "X = bank_full.drop(['y'], axis = 1).values\n",
    "y = bank_full['y'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 'housemaid' 'single' 'tertiary' 'no' 453 'no' 'no' 'cellular' 13\n",
      "  'aug' 126 2 -1 0 'unknown']\n",
      " [55 'services' 'married' 'secondary' 'no' 0 'no' 'no' 'cellular' 22\n",
      "  'oct' 102 1 106 1 'failure']\n",
      " [56 'services' 'divorced' 'secondary' 'no' 935 'no' 'no' 'cellular' 2\n",
      "  'jun' 136 1 96 3 'failure']\n",
      " [47 'housemaid' 'single' 'tertiary' 'no' 3232 'no' 'no' 'telephone' 6\n",
      "  'oct' 541 1 204 3 'failure']\n",
      " [39 'technician' 'married' 'tertiary' 'no' 508 'no' 'no' 'cellular' 2\n",
      "  'nov' 154 3 -1 0 'unknown']\n",
      " [36 'technician' 'single' 'tertiary' 'no' 306 'no' 'no' 'cellular' 14\n",
      "  'aug' 111 2 -1 0 'unknown']\n",
      " [33 'management' 'single' 'tertiary' 'no' 6807 'no' 'no' 'cellular' 20\n",
      "  'apr' 163 1 -1 0 'unknown']\n",
      " [36 'management' 'married' 'tertiary' 'no' 669 'no' 'no' 'unknown' 9\n",
      "  'jun' 91 1 -1 0 'unknown']\n",
      " [52 'retired' 'married' 'secondary' 'no' 1956 'no' 'no' 'unknown' 6\n",
      "  'jun' 384 2 -1 0 'unknown']\n",
      " [53 'management' 'married' 'tertiary' 'no' 694 'no' 'no' 'unknown' 18\n",
      "  'jun' 130 6 -1 0 'unknown']]\n",
      "(30291, 16)\n"
     ]
    }
   ],
   "source": [
    "print (X_train[:10])\n",
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no' 'no' 'no' ... 'yes' 'no' 'no']\n"
     ]
    }
   ],
   "source": [
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'poutcome', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Identify numeric and categorical variables \n",
    "total_columns = bank_full.columns\n",
    "print (total_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n"
     ]
    }
   ],
   "source": [
    "num_columns = list(bank_full._get_numeric_data().columns)\n",
    "print (num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poutcome', 'default', 'marital', 'loan', 'y', 'contact', 'education', 'month', 'job', 'housing']\n"
     ]
    }
   ],
   "source": [
    "cat_columns = list(set(total_columns) - set(num_columns))\n",
    "print (cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply one-hot encoding/dummy coding\n",
    "from sklearn import preprocessing \n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(bank_full[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['failure', 'other', 'success', 'unknown'], dtype=object), array(['no', 'yes'], dtype=object), array(['divorced', 'married', 'single'], dtype=object), array(['no', 'yes'], dtype=object), array(['no', 'yes'], dtype=object), array(['cellular', 'telephone', 'unknown'], dtype=object), array(['primary', 'secondary', 'tertiary', 'unknown'], dtype=object), array(['apr', 'aug', 'dec', 'feb', 'jan', 'jul', 'jun', 'mar', 'may',\n",
      "       'nov', 'oct', 'sep'], dtype=object), array(['admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management',\n",
      "       'retired', 'self-employed', 'services', 'student', 'technician',\n",
      "       'unemployed', 'unknown'], dtype=object), array(['no', 'yes'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "#View the categories of each feature determined during fitting\n",
    "print (enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#View dummy values\n",
    "preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "print (enc.transform(bank_full[cat_columns]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization,mean removal and variance scaling on the train set\n",
    "X_train_df = pd.DataFrame(data = X_train, columns = bank_full.drop(['y'], axis = 1).columns)\n",
    "X_train_df_num = X_train_df[num_columns]\n",
    "X_scaled = preprocessing.scale(X_train_df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12412874, -0.30427051, -0.33930524, ..., -0.24359804,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [ 1.32276575, -0.457537  ,  0.74284423, ..., -0.5618293 ,\n",
       "         0.65312148,  0.22504206],\n",
       "       [ 1.41687707, -0.14119225, -1.66193236, ..., -0.5618293 ,\n",
       "         0.55372102,  1.28700638],\n",
       "       ...,\n",
       "       [-0.65357211, -0.01194766, -0.09882758, ..., -0.5618293 ,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [-0.74768343, -0.40171145, -1.06073821, ..., -0.5618293 ,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [-0.2771268 , -0.4714088 ,  0.6226054 , ...,  2.30225204,\n",
       "        -0.41046341, -0.3059401 ]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08890415, -0.26130175,  0.02141125, ..., -0.5618293 ,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [ 0.56987513,  0.77536168, -0.82026055, ..., -0.24359804,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [-1.50057405, -0.27551189,  0.50236657, ..., -0.5618293 ,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       ...,\n",
       "       [-0.2771268 , -0.457537  ,  0.14165008, ..., -0.24359804,\n",
       "        -0.41046341, -0.3059401 ],\n",
       "       [-0.93590609,  0.52871427,  1.70475486, ..., -0.5618293 ,\n",
       "         0.45432056,  0.22504206],\n",
       "       [-0.65357211,  1.57688115,  0.26188891, ..., -0.5618293 ,\n",
       "        -0.41046341, -0.3059401 ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the mean and standard deviation on the testing set\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_df_num)\n",
    "X_test_df = pd.DataFrame(data = X_test, columns = bank_full.drop(['y'], axis = 1).columns)\n",
    "X_test_df_num = X_test_df[num_columns]\n",
    "scaler.transform(X_test_df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
